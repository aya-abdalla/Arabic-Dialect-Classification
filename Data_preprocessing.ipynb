{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from pyarabic.araby import strip_tashkeel,strip_tatweel,normalize_ligature\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ipynb.fs.full.Data_fetching import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df): \n",
    "    unique_Dialect = df['dialect'].unique()\n",
    "    label2id={label:idx for idx,label in enumerate(unique_Dialect)}\n",
    "    id2label={idx:label for label,idx in label2id.items()}\n",
    "    encoder= ce.OrdinalEncoder(cols=['dialect'],return_df=True,\n",
    "                           mapping=[{'col':'dialect',\n",
    "    'mapping':label2id}])\n",
    "    df['transformed'] = encoder.fit_transform(df['dialect'])\n",
    "    return df \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  transformed\n",
       "0  1175358310087892992      IQ            0\n",
       "1  1175416117793349632      IQ            0\n",
       "2  1175450108898565888      IQ            0\n",
       "3  1175471073770573824      IQ            0\n",
       "4  1175496913145217024      IQ            0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for cleaning\n",
    "df=pd.read_csv(\"dialect_dataset.csv\",converters={'id': str})\n",
    "df.head()\n",
    "tweetdic=fetch_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>transformed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>@Nw8ieJUwaCAAreT ŸÑŸÉŸÜ ÿ®ÿßŸÑŸÜŸáÿßŸäÿ© .. ŸäŸÜÿ™ŸÅÿ∂ .. Ÿäÿ∫Ÿäÿ± .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>@7zNqXP0yrODdRjK ŸäÿπŸÜŸä Ÿáÿ∞ÿß ŸÖÿ≠ÿ≥Ÿàÿ® ÿπŸÑŸâ ÿßŸÑÿ®ÿ¥ÿ± .. ÿ≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>@KanaanRema ŸÖÿ®ŸäŸÜ ŸÖŸÜ ŸÉŸÑÿßŸÖŸá ÿÆŸÑŸäÿ¨Ÿä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>@HAIDER76128900 Ÿäÿ≥ŸÑŸÖŸÑŸä ŸÖÿ±Ÿàÿ±ŸÉ Ÿàÿ±Ÿàÿ≠ŸÉ ÿßŸÑÿ≠ŸÑŸàŸáüíê</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>@hmo2406 ŸàŸäŸÜ ŸáŸÑ ÿßŸÑÿ∫Ÿäÿ®Ÿá  ÿßÿÆ ŸÖÿ≠ŸÖÿØ üå∏üå∫</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  transformed  \\\n",
       "0  1175358310087892992      IQ            0   \n",
       "1  1175416117793349632      IQ            0   \n",
       "2  1175450108898565888      IQ            0   \n",
       "3  1175471073770573824      IQ            0   \n",
       "4  1175496913145217024      IQ            0   \n",
       "\n",
       "                                                text  \n",
       "0   @Nw8ieJUwaCAAreT ŸÑŸÉŸÜ ÿ®ÿßŸÑŸÜŸáÿßŸäÿ© .. ŸäŸÜÿ™ŸÅÿ∂ .. Ÿäÿ∫Ÿäÿ± .  \n",
       "1  @7zNqXP0yrODdRjK ŸäÿπŸÜŸä Ÿáÿ∞ÿß ŸÖÿ≠ÿ≥Ÿàÿ® ÿπŸÑŸâ ÿßŸÑÿ®ÿ¥ÿ± .. ÿ≠...  \n",
       "2                    @KanaanRema ŸÖÿ®ŸäŸÜ ŸÖŸÜ ŸÉŸÑÿßŸÖŸá ÿÆŸÑŸäÿ¨Ÿä  \n",
       "3         @HAIDER76128900 Ÿäÿ≥ŸÑŸÖŸÑŸä ŸÖÿ±Ÿàÿ±ŸÉ Ÿàÿ±Ÿàÿ≠ŸÉ ÿßŸÑÿ≠ŸÑŸàŸáüíê  \n",
       "4                 @hmo2406 ŸàŸäŸÜ ŸáŸÑ ÿßŸÑÿ∫Ÿäÿ®Ÿá  ÿßÿÆ ŸÖÿ≠ŸÖÿØ üå∏üå∫  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['id'].map(tweetdic)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sent):\n",
    "    \"\"\"clean data from any English char, emoticons, underscore, and repeated > 2\n",
    "    str -> str\"\"\"\n",
    "    p1 = re.compile('\\W')\n",
    "    p2 = re.compile('\\s+')\n",
    "    sent = ReplaceThreeOrMore(sent)\n",
    "    \n",
    "    sent = sent.replace('_', ' ')\n",
    "    sent = re.sub(r'[A-Za-z0-9]', r'', sent)\n",
    "    \n",
    "    sent = re.sub(p1, ' ', sent)\n",
    "    \n",
    "    sent = re.sub(p2, ' ', sent)\n",
    "   \n",
    "    return sent\n",
    "\n",
    "def ReplaceThreeOrMore(s):\n",
    "    # pattern to look for three or more repetitions of any character, including\n",
    "    # newlines.\n",
    "     \n",
    "    pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL) #3 or more \n",
    " \n",
    "    return pattern.sub(r\"\\1\", s)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unicode_diac(text):\n",
    "    \"\"\"Takes Arabic in utf-8 and returns same text without diac\"\"\"\n",
    "    # Replace diacritics with nothing\n",
    "    text = text.replace(u\"\\u064B\", \"\")  # fatHatayn\n",
    "    text = text.replace(u\"\\u064C\", \"\")  # Dammatayn\n",
    "    text = text.replace(u\"\\u064D\", \"\")  # kasratayn\n",
    "    text = text.replace(u\"\\u064E\", \"\")  # fatHa\n",
    "    text = text.replace(u\"\\u064F\", \"\")  # Damma\n",
    "    text = text.replace(u\"\\u0650\", \"\")  # kasra\n",
    "    text = text.replace(u\"\\u0651\", \"\")  # shaddah\n",
    "    text = text.replace(u\"\\u0652\", \"\")  # sukuun\n",
    "    text = text.replace(u\"\\u0670\", \"`\")  # dagger 'alif\n",
    "    return text\n",
    "\n",
    "def norm_alif(text):\n",
    "    text = text.replace(u\"\\u0625\", u\"\\u0627\")  # HAMZA below, with LETTER ALEF \n",
    "    text = text.replace(u\"\\u0622\", u\"\\u0627\")  # ALEF WITH MADDA ABOVE, with LETTER ALEF\n",
    "    text = text.replace(u\"\\u0623\", u\"\\u0627\")  # ALEF WITH HAMZA ABOVE, with LETTER ALEF\n",
    "    return text\n",
    "\n",
    "def norm_taa(text):\n",
    "    text=text.replace(u\"\\u0629\", u\"\\u0647\") # taa' marbuuTa, with haa'\n",
    "    \n",
    "    return text\n",
    "def norm_yaa(text):  \n",
    "    if len(text)!=0:\n",
    "        if text[-1] == u\"\\u064A\":  \n",
    "            s = list(text)\n",
    "            s[-1]=u\"\\u0649\"\n",
    "            text=\"\".join(s)\n",
    "    #  text = text.replace(u\"\\u064A\", u\"\\u0649\")  # yaa' with 'alif maqSuura  \n",
    "          \n",
    "    return text \n",
    "def NormForWord2Vec(text):\n",
    "    text=norm_taa(text)\n",
    "    text=norm_yaa(text)\n",
    "    text=norm_alif(text)\n",
    "    return text\n",
    "\n",
    "def remove_nonunicode2(Tweet):\n",
    "    ## defining set of unicode ##\n",
    "    #u\"\"\n",
    "    #Tweet=Tweet.decode(\"utf-8\")\n",
    "    UniLex={ ## This is list of all arabic unicode characters in addition to space (to separate words)\n",
    "            u\"\\u0622\",\n",
    "            u\"\\u0626\",\n",
    "            u\"\\u0628\",\n",
    "            u\"\\u062a\",\n",
    "            u\"\\u062c\",\n",
    "            u\"\\u06af\",\n",
    "            u\"\\u062e\",\n",
    "            u\"\\u0630\",\n",
    "            u\"\\u0632\",\n",
    "            u\"\\u0634\",\n",
    "            u\"\\u0636\",\n",
    "            u\"\\u0638\",\n",
    "            u\"\\u063a\",\n",
    "            u\"\\u0640\",\n",
    "            u\"\\u0642\",\n",
    "            u\"\\u0644\",\n",
    "            u\"\\u0646\",\n",
    "            u\"\\u0648\",\n",
    "            u\"\\u064a\",\n",
    "            u\"\\u0670\",\n",
    "            u\"\\u067e\",\n",
    "            u\"\\u0686\",\n",
    "            u\"\\u0621\",\n",
    "            u\"\\u0623\",\n",
    "            u\"\\u0625\",\n",
    "            u\"\\u06a4\",\n",
    "            u\"\\u0627\",\n",
    "            u\"\\u0629\",\n",
    "            u\"\\u062b\",\n",
    "            u\"\\u062d\",\n",
    "            u\"\\u062f\",\n",
    "            u\"\\u0631\",\n",
    "            u\"\\u0633\",\n",
    "            u\"\\u0635\",\n",
    "            u\"\\u0637\",\n",
    "            u\"\\u0639\",\n",
    "            u\"\\u0641\",\n",
    "            u\"\\u0643\",\n",
    "            u\"\\u0645\",\n",
    "            u\"\\u0647\",\n",
    "            u\"\\u0649\",\n",
    "            u\"\\u0671\",\n",
    "            ' ',\n",
    "            '\\n'\n",
    "          }\n",
    "    fin_tweet=\"\"\n",
    "    for c in Tweet:\n",
    "        if c in UniLex:\n",
    "           fin_tweet=fin_tweet+c\n",
    "    return fin_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_single_char_words(Tweet):\n",
    "    parts = Tweet.split(\" \")\n",
    "    cleaned_line_parts = []\n",
    "    for P in parts:\n",
    "        if len(P) != 1:\n",
    "            cleaned_line_parts.append(P)\n",
    "    cleaned_line = ' '.join(cleaned_line_parts)\n",
    "    return cleaned_line\n",
    "def clean_unicode(Tweet):\n",
    "    if(isinstance(Tweet, str)==False):\n",
    "        print(Tweet)\n",
    "    tweet=normalize(Tweet.strip(\"\\n\"))\n",
    "    if len(tweet) !=0:\n",
    "        sentence = []\n",
    "        for word in tweet.split(\" \"):\n",
    "            word = remove_unicode_diac(word)\n",
    "            word = norm_alif(word)\n",
    "            word = norm_taa(word)\n",
    "            word = norm_yaa(word)\n",
    "            word = normalize(word)\n",
    "            sentence.append(word)\n",
    "        tweet = ' '.join(sentence)\n",
    "        tweet =remove_nonunicode2(tweet)\n",
    "        tweet =eliminate_single_char_words(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fineText'] = df['text'].map(lambda x:clean_unicode(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf= df.copy()\n",
    "del df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458197, 4), (458197, 4))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf=pd.read_csv(\"transformed.csv\")\n",
    "newdf.shape , df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>transformed</th>\n",
       "      <th>fineText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>ŸÑŸÉŸÜ ÿ®ÿßŸÑŸÜŸáÿßŸäŸá ŸäŸÜÿ™ŸÅÿ∂ Ÿäÿ∫Ÿäÿ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>ŸäÿπŸÜŸâ Ÿáÿ∞ÿß ŸÖÿ≠ÿ≥Ÿàÿ® ÿπŸÑŸâ ÿßŸÑÿ®ÿ¥ÿ± ÿ≠ŸäŸàŸÜŸá ŸàŸàÿ≠ÿ¥ŸäŸá Ÿàÿ™ÿ∑ŸÑÿ®ŸàŸÜ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>ŸÖÿ®ŸäŸÜ ŸÖŸÜ ŸÉŸÑÿßŸÖŸá ÿÆŸÑŸäÿ¨Ÿâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>Ÿäÿ≥ŸÑŸÖŸÑŸâ ŸÖÿ±Ÿàÿ±ŸÉ Ÿàÿ±Ÿàÿ≠ŸÉ ÿßŸÑÿ≠ŸÑŸàŸá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>0</td>\n",
       "      <td>ŸàŸäŸÜ ŸáŸÑ ÿßŸÑÿ∫Ÿäÿ®Ÿá ÿßÿÆ ŸÖÿ≠ŸÖÿØ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id dialect  transformed  \\\n",
       "0           0  1175358310087892992      IQ            0   \n",
       "1           1  1175416117793349632      IQ            0   \n",
       "2           2  1175450108898565888      IQ            0   \n",
       "3           3  1175471073770573824      IQ            0   \n",
       "4           4  1175496913145217024      IQ            0   \n",
       "\n",
       "                                            fineText  \n",
       "0                           ŸÑŸÉŸÜ ÿ®ÿßŸÑŸÜŸáÿßŸäŸá ŸäŸÜÿ™ŸÅÿ∂ Ÿäÿ∫Ÿäÿ±   \n",
       "1   ŸäÿπŸÜŸâ Ÿáÿ∞ÿß ŸÖÿ≠ÿ≥Ÿàÿ® ÿπŸÑŸâ ÿßŸÑÿ®ÿ¥ÿ± ÿ≠ŸäŸàŸÜŸá ŸàŸàÿ≠ÿ¥ŸäŸá Ÿàÿ™ÿ∑ŸÑÿ®ŸàŸÜ...  \n",
       "2                                ŸÖÿ®ŸäŸÜ ŸÖŸÜ ŸÉŸÑÿßŸÖŸá ÿÆŸÑŸäÿ¨Ÿâ  \n",
       "3                         Ÿäÿ≥ŸÑŸÖŸÑŸâ ŸÖÿ±Ÿàÿ±ŸÉ Ÿàÿ±Ÿàÿ≠ŸÉ ÿßŸÑÿ≠ŸÑŸàŸá   \n",
       "4                             ŸàŸäŸÜ ŸáŸÑ ÿßŸÑÿ∫Ÿäÿ®Ÿá ÿßÿÆ ŸÖÿ≠ŸÖÿØ   "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
